<!DOCTYPE html PUBLIC ""
    "">
<html><head><meta charset="UTF-8" /><title>clj-ml.classifiers documentation</title><link rel="stylesheet" type="text/css" href="css/default.css" /><link rel="stylesheet" type="text/css" href="css/highlight.css" /><script type="text/javascript" src="js/highlight.min.js"></script><script type="text/javascript" src="js/jquery.min.js"></script><script type="text/javascript" src="js/page_effects.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body><div id="header"><h2>Generated by <a href="https://github.com/weavejester/codox">Codox</a></h2><h1><a href="index.html"><span class="project-title"><span class="project-name">Clj-ml</span> <span class="project-version">0.8.9</span></span></a></h1></div><div class="sidebar primary"><h3 class="no-link"><span class="inner">Project</span></h3><ul class="index-link"><li class="depth-1 "><a href="index.html"><div class="inner">Index</div></a></li></ul><h3 class="no-link"><span class="inner">Namespaces</span></h3><ul><li class="depth-1"><div class="no-link"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>clj-ml</span></div></div></li><li class="depth-2 branch"><a href="clj-ml.attribute-selection.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>attribute-selection</span></div></a></li><li class="depth-2 branch current"><a href="clj-ml.classifiers.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>classifiers</span></div></a></li><li class="depth-2 branch"><a href="clj-ml.clusterers.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>clusterers</span></div></a></li><li class="depth-2 branch"><a href="clj-ml.data.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>data</span></div></a></li><li class="depth-2 branch"><a href="clj-ml.distance-functions.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>distance-functions</span></div></a></li><li class="depth-2 branch"><a href="clj-ml.filters.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>filters</span></div></a></li><li class="depth-2 branch"><a href="clj-ml.io.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>io</span></div></a></li><li class="depth-2 branch"><a href="clj-ml.kernel-functions.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>kernel-functions</span></div></a></li><li class="depth-2 branch"><a href="clj-ml.options-utils.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>options-utils</span></div></a></li><li class="depth-2 branch"><a href="clj-ml.public-datasets.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>public-datasets</span></div></a></li><li class="depth-2"><a href="clj-ml.utils.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>utils</span></div></a></li></ul></div><div class="sidebar secondary"><h3><a href="#top"><span class="inner">Public Vars</span></a></h3><ul><li class="depth-1"><a href="clj-ml.classifiers.html#var-classifier-classify"><div class="inner"><span>classifier-classify</span></div></a></li><li class="depth-1"><a href="clj-ml.classifiers.html#var-classifier-copy"><div class="inner"><span>classifier-copy</span></div></a></li><li class="depth-1"><a href="clj-ml.classifiers.html#var-classifier-copy-and-train"><div class="inner"><span>classifier-copy-and-train</span></div></a></li><li class="depth-1"><a href="clj-ml.classifiers.html#var-classifier-evaluate"><div class="inner"><span>classifier-evaluate</span></div></a></li><li class="depth-1"><a href="clj-ml.classifiers.html#var-classifier-label"><div class="inner"><span>classifier-label</span></div></a></li><li class="depth-1"><a href="clj-ml.classifiers.html#var-classifier-predict-numeric"><div class="inner"><span>classifier-predict-numeric</span></div></a></li><li class="depth-1"><a href="clj-ml.classifiers.html#var-classifier-predict-probability"><div class="inner"><span>classifier-predict-probability</span></div></a></li><li class="depth-1"><a href="clj-ml.classifiers.html#var-classifier-train"><div class="inner"><span>classifier-train</span></div></a></li><li class="depth-1"><a href="clj-ml.classifiers.html#var-classifier-update"><div class="inner"><span>classifier-update</span></div></a></li><li class="depth-1"><a href="clj-ml.classifiers.html#var-make-classifier"><div class="inner"><span>make-classifier</span></div></a></li><li class="depth-1"><a href="clj-ml.classifiers.html#var-make-classifier-with"><div class="inner"><span>make-classifier-with</span></div></a></li></ul></div><div class="namespace-docs" id="content"><h1 class="anchor" id="top">clj-ml.classifiers</h1><div class="doc"><pre class="plaintext">This namespace contains several functions for building classifiers using different
classification algorithms: Bayes networks, multilayer perceptron, decision tree or
support vector machines are available. Some of these classifiers have incremental
versions so they can be built without having all the dataset instances in memory.

Functions for evaluating the classifiers built using cross validation or a training
set are also provided.

A sample use of the API for classifiers is shown below:

 (use 'clj-ml.classifiers)

 ; Building a classifier using a  C4.5 decision tree
 (def *classifier* (make-classifier :decision-tree :c45))

 ; We set the class attribute for the loaded dataset.
 ; *dataset* is supposed to contain a set of instances.
 (dataset-set-class *dataset* 4)

 ; Training the classifier
 (classifier-train *classifier* *dataset*)

 ; We evaluate the classifier using a test dataset
 (def *evaluation*   (classifier-evaluate *classifier* :dataset *dataset* *trainingset*))

 ; We retrieve some data from the evaluation result
 (:kappa *evaluation*)
 (:root-mean-squared-error *evaluation*)
 (:precision *evaluation*)

 ; A trained classifier can be used to classify new instances
 (def *to-classify* (make-instance *dataset*  {:class :Iris-versicolor
                                               :petalwidth 0.2
                                               :petallength 1.4
                                               :sepalwidth 3.5
                                               :sepallength 5.1}))

 ; We retrieve the index of the class value assigned by the classifier
 (classifier-classify *classifier* *to-classify*)

 ; We retrieve a symbol with the value assigned by the classifier
 ; and assigns it to a certain instance
 (classifier-label *classifier* *to-classify*)

A classifier can also be trained using cross-validation:

 (classifier-evaluate *classifier* :cross-validation *dataset* 10)

Finally a classifier can be stored in a file for later use:

 (use 'clj-ml.utils)

 (serialize-to-file *classifier*
  "/Users/antonio.garrote/Desktop/classifier.bin")</pre></div><div class="public anchor" id="var-classifier-classify"><h3>classifier-classify</h3><div class="usage"><code>(classifier-classify classifier instance)</code></div><div class="doc"><pre class="plaintext">Classifies an instance using the provided classifier. Returns the
class as a keyword.</pre></div></div><div class="public anchor" id="var-classifier-copy"><h3>classifier-copy</h3><div class="usage"><code>(classifier-copy classifier)</code></div><div class="doc"><pre class="plaintext">Performs a deep copy of the classifier
</pre></div></div><div class="public anchor" id="var-classifier-copy-and-train"><h3>classifier-copy-and-train</h3><div class="usage"><code>(classifier-copy-and-train classifier dataset)</code></div><div class="doc"><pre class="plaintext">Performs a deep copy of the classifier, trains the copy, and returns it.
</pre></div></div><div class="public anchor" id="var-classifier-evaluate"><h3>classifier-evaluate</h3><h4 class="type">multimethod</h4><div class="usage"></div><div class="doc"><pre class="plaintext">Evaluates a trained classifier using the provided dataset or cross-validation.
The first argument must be the classifier to evaluate, the second argument is
the kind of evaluation to do.
Two possible evaluations ara availabe: dataset and cross-validations. The values
for the second argument can be:

 - :dataset
 - :cross-validation

 * :dataset

 If dataset evaluation is desired, the function call must receive as the second
 parameter the keyword :dataset and as third and fourth parameters the original
 dataset used to build the classifier and the training data:

   (classifier-evaluate *classifier* :dataset *training* *evaluation*)

 * :cross-validation

 If cross-validation is desired, the function call must receive as the second
 parameter the keyword :cross-validation and as third and fourth parameters the dataset
 where for training and the number of folds.

   (classifier-evaluate *classifier* :cross-validation *training* 10)

 An optional seed can be provided for generation of the cross validation folds.

   (classifier-evaluate *classifier* :cross-validation *training* 10 {:random-seed 29})

 The metrics available in the evaluation are listed below:

 - :correct
     Number of instances correctly classified
 - :incorrect
     Number of instances incorrectly evaluated
 - :unclassified
     Number of instances incorrectly classified
 - :percentage-correct
     Percentage of correctly classified instances
 - :percentage-incorrect
     Percentage of incorrectly classified instances
 - :percentage-unclassified
     Percentage of not classified instances
 - :error-rate
 - :mean-absolute-error
 - :relative-absolute-error
 - :root-mean-squared-error
 - :root-relative-squared-error
 - :correlation-coefficient
 - :average-cost
 - :kappa
     The kappa statistic
 - :kb-information
 - :kb-mean-information
 - :kb-relative-information
 - :sf-entropy-gain
 - :sf-mean-entropy-gain
 - :roc-area
 - :false-positive-rate
 - :false-negative-rate
 - :f-measure
 - :precision
 - :recall
 - :evaluation-object
     The underlying Weka's Java object containing the evaluation
</pre></div></div><div class="public anchor" id="var-classifier-label"><h3>classifier-label</h3><div class="usage"><code>(classifier-label classifier instance)</code></div><div class="doc"><pre class="plaintext">Classifies and assign a label to a dataset instance.
The function returns the newly classified instance. This call is
destructive, the instance passed as an argument is modified.</pre></div></div><div class="public anchor" id="var-classifier-predict-numeric"><h3>classifier-predict-numeric</h3><div class="usage"><code>(classifier-predict-numeric classifier instance)</code></div><div class="doc"><pre class="plaintext">Predicts the class attribute of an instance using the provided
classifier. Returns the value as a floating-point value (e.g., for
regression).</pre></div></div><div class="public anchor" id="var-classifier-predict-probability"><h3>classifier-predict-probability</h3><div class="usage"><code>(classifier-predict-probability classifier instance)</code></div><div class="doc"><pre class="plaintext">Classifies an instance using the provided classifier. Returns the
probability distribution across classes for the instance</pre></div></div><div class="public anchor" id="var-classifier-train"><h3>classifier-train</h3><div class="usage"><code>(classifier-train classifier dataset)</code></div><div class="doc"><pre class="plaintext">Trains a classifier with the given dataset as the training data.
</pre></div></div><div class="public anchor" id="var-classifier-update"><h3>classifier-update</h3><div class="usage"><code>(classifier-update classifier instance-s)</code></div><div class="doc"><pre class="plaintext">If the classifier is updateable it updates the classifier with the given instance or set of instances.
</pre></div></div><div class="public anchor" id="var-make-classifier"><h3>make-classifier</h3><h4 class="type">multimethod</h4><div class="usage"></div><div class="doc"><pre class="plaintext">Creates a new classifier for the given kind algorithm and options.

The first argument identifies the kind of classifier and the second
argument the algorithm to use, e.g. :decision-tree :c45.

The classifiers currently supported are:

  - :lazy :ibk
  - :decision-tree :c45
  - :decision-tree :boosted-stump
  - :decision-tree :m5p
  - :decision-tree :random-forest
  - :decision-tree :rotation-forest
  - :rule :m5rules
  - :bayes :naive
  - :neural-network :multilayer-perceptron
  - :support-vector-machine :smo
  - :support-vector-machine :smo-regression
  - :support-vector-machine :spegasos
  - :support-vector-machine :libsvm
  - :support-vector-machine :libsvm-grid
  - :regression :linear
  - :regression :logistic
  - :regression :pace
  - :regression :pls
  - :regression :boosted
  - :regression :partial-least-squares
  - :meta :attributeselectedclassifier
  - :meta :bagging
  - :meta :random-subspace
  - :meta :random-committee
  - :meta :stacking
  - :meta :adaboost-m1
  - :meta :raced-incremental-logit-boost

Optionally, a map of options can also be passed as an argument with
a set of classifier specific options.

This is the description of the supported classifiers and the accepted
option parameters for each of them:

 * :lazy :ibk

   K-nearest neighbor classification.

   Parameters:

     - :inverse-weighted
         Neighbors will be weighted by the inverse of their distance when voting. (default equal weighting)
         Sample value: true
     - :similarity-weighted
         Neighbors will be weighted by their similarity when voting. (default equal weighting)
         Sample value: true
     - :no-normalization
         Turns off normalization.
         Sample value: true
     - :num-neighbors
         Set the number of nearest neighbors to use in prediction (default 1)
         Sample value: 3

 * :decision-tree :c45

   A classifier building a pruned or unpruned C 4.5 decision tree using
   Weka J 4.8 implementation.

   Parameters:

     - :unpruned
         Use unpruned tree. Sample value: true
     - :reduce-error-pruning
         Sample value: true
     - :only-binary-splits
         Sample value: true
     - :no-raising
         Sample value: true
     - :no-cleanup
         Sample value: true
     - :laplace-smoothing
         For predicted probabilities. Sample value: true
     - :pruning-confidence
         Threshold for pruning. Default value: 0.25
     - :minimum-instances
         Minimum number of instances per leave. Default value: 2
     - :pruning-number-folds
         Set number of folds for reduced error pruning. Default value: 3
     - :random-seed
         Seed for random data shuffling. Default value: 1

 * :bayes :naive

   Classifier based on the Bayes' theorem with strong independence assumptions, among the
   probabilistic variables.

   Parameters:

     - :kernel-estimator
         Use kernel desity estimator rather than normal. Sample value: true
     - :supervised-discretization
         Use supervised discretization to to process numeric attributes (see :supervised-discretize
         filter in clj-ml.filters/make-filter function). Sample value: true

 * :neural-network :multilayer-perceptron

   Classifier built using a feedforward artificial neural network with three or more layers
   of neurons and nonlinear activation functions. It is able to distinguish data that is not
   linearly separable.

   Parameters:

     - :no-nominal-to-binary
         A :nominal-to-binary filter will not be applied by default. (see :supervised-nominal-to-binary
         filter in clj-ml.filters/make-filter function). Default value: false
     - :no-numeric-normalization
         A numeric class will not be normalized. Default value: false
     - :no-normalization
         No attribute will be normalized. Default value: false
     - :no-reset
         Reseting the network will not be allowed. Default value: false
     - :learning-rate-decay
         Learning rate decay will occur. Default value: false
     - :learning-rate
         Learning rate for the backpropagation algorithm. Value should be between [0,1].
         Default value: 0.3
     - :momentum
         Momentum rate for the backpropagation algorithm. Value shuld be between [0,1].
         Default value: 0.2
     - :epochs
         Number of iteration to train through. Default value: 500
     - :percentage-validation-set
         Percentage size of validation set to use to terminate training. If it is not zero
         it takes precende over the number of epochs to finish training. Values should be
         between [0,100]. Default value: 0
     - :random-seed
         Value of the seed for the random generator. Values should be longs greater than
         0. Default value: 1
     - :threshold-number-errors
         The consequetive number of errors allowed for validation testing before the network
         terminates. Values should be greater thant 0. Default value: 20

 * :support-vector-machine :smo

   Support vector machine (SVM) classifier built using the sequential minimal optimization (SMO)
   training algorithm.

   Parameters:

     - :fit-logistic-models
         Fit logistic models to SVM outputs. Default value :false
     - :complexity-constant
         The complexity constance. Default value: 1
     - :tolerance
         Tolerance parameter. Default value: 1.0e-3
     - :epsilon-roundoff
         Epsilon round-off error. Default value: 1.0e-12
     - :folds-for-cross-validation
         Number of folds for the internal cross-validation. Sample value: 10
     - :random-seed
         Value of the seed for the random generator. Values should be longs greater than
         0. Default value: 1

  * :support-vector-machine :libsvm

    TODO

  * :regression :linear

   Parameters:

     - :attribute-selection
         Set the attribute selection method to use. 1 = None, 2 = Greedy. (default 0 = M5' method)
     - :keep-colinear
         Do not try to eliminate colinear attributes.
     - :ridge
         Set ridge parameter (default 1.0e-8).

  * :regression :logistic

   Parameters:

     - :max-iterations
         Set the maximum number of iterations (default -1, until convergence).
     - :ridge
         Set the ridge in the log-likelihood.
</pre></div></div><div class="public anchor" id="var-make-classifier-with"><h3>make-classifier-with</h3><div class="usage"><code>(make-classifier-with kind algorithm classifier-class options)</code></div><div class="doc"><pre class="plaintext"></pre></div></div></div></body></html>